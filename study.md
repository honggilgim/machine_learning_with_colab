# 머신러닝 이론

## 머신러닝 관련 공부

### 머신러닝이란?

인공지능의 하위 집합. 경험을 통해 자동으로 개선하는 컴퓨터의 알고리즘 지도 학습과 비지도 학습으로 분류되며, 지도 학습은 훈련 데이터로부터 하나의 함수를 유출해내기 위한 학습이고 비지도 학습은, 알고리즘 자체가 데이터를 학습하는 것.

지도 학습과 비지도 학습의 중요한 차이점은, 지도 학습은 데이터를 학습하는 일에 정답을 알려주지만 비지도 학습은 정답을 알려주지 않는다. 각 지도 학습과 비지도 학습에 대해서도 공부해 볼 생각이다.

### 지도학습

지도 학습이란, 함수의 매개 변수를 찾아내는 학습이다. 입력된 데이터들로부터 매개 변수를 찾아내어 이를 함수로 만든다. 예시 : 분류, 회귀

### 비지도 학습

비지도 학습은, 간단히 데이터의 경계를 찾아내는 작업이다. 데이터들의 경계를 찾아내어 데이터가 무엇인지 확인한다. 예시로는, 클러스터링이 있다.

## 선형 회귀 분석

### 1. 얇은 분석, 깊은 분석

목적 : 데이터란 우리가 가지는 어떤 사건이나 현상에 대한 과거의 기록. 데이터로 만들어진 순간 과거의 기록이 되는데, 이 데이터를 분석한다면 주요 사건이나 현상의 과거를 이해할 수 있음. 과거에 대한 이해를 바탕으로 앞으로 일어날 일도 예측이 가능.

추론과 예측을 위한 분석의 궁극적인 목적은 x로부터 y를 아는 것. 추론은 x에 임의의 계산을 적용하여 y가 나오는 것을 아는 것이고, 예측은 x만 알고 y는 모르는 상태에서 y를 미리 계산하는 것.

XAI : 설명 가능한 인공지능

### 2. 선형 회귀 분석

평균이나 편차 등 데이터에 대한 요약 정보를 사용해서 분석이 가능. 특히 공분산이나 상관계수로 두 변수의 관계를 살펴볼 수 있으며, 한 변수가 움직일 때 다른 변수가 어떻게 움직이는지에 대한 정보를 제공. 그러나 이러한 요약 정보는 두 변수의 관계를 나타낼 뿐, 모형화는 불가능.

선형 회귀는 주어진 데이터에 y절편과 기울기로 나타낸 직선을 적합시키는 과정으로 볼 수 있음. 미지수인 y절편과 기울기를 통해 데이터를 추정 가능.

잔차 : 선형 회귀 식에 각 예측한 y와 실제 y의 차이.

잔차는 작을수록 좋음.

최소제곱법 : 잔차의 제곱합을 최소화하는 y절편과 기울기를 찾는 방법

선형 회귀 분석은 독립 변수가 종속 변수에 어떤 효과를 주는지를 모형화하는 데 사용. 다중 선형 회구 분석은 독립 변수가 여러 개 주어진 경우 사용.


### 확장 : 포아송 회귀모형

선형 회귀모형은 변수 y가 수치인 경우 사용. y는 수치이면서 잔차의 분포는 등 분산을 가지고 잔차는 정규 분포를 따르는 것으로 가정. 변수 x와 y의 관계는 선형 관계여야 함.

0보다 큰 빈도수 y를 찾는 일에는, 포아송 회귀모형을 사용. 포아송 회귀모형도 x와 y의 관계를 식으로 나타내는데, x와 y의 관계가 비선형이기에 직선식으로 나타내려면 x와 y의 관계를 선형 관계로 변형해야 함. y에 로그 함수를 적용하여 log y는 x와 선형 관계를 가지게 되면서 직선식으로 나타낼 수 있음.

### 확장 : 로지스틱 회귀모형

종속 변수 y가 수치형이 아닌 범주형 자료인 경우, 앞에서 살펴본 일반적인 선형 회귀 분석을 사용하면 안됨.

y값이 범주형인 것을 고려할 수 있는, 로지스틱 회귀모형을 사용할 수 있음.

y는 이산적인 값을 갖기에 이산형 변수에 대해 직선식으로 모델링하는 것으로 이해가 가능.

로지스틱 회귀모형은 y가 범주형이거나 이항이고, x는 범주형 또는 수치형인 경우에 사용이 가능.
