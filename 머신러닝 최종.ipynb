{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "응용수학_2022년_1학기_2016038005_김홍길.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcgzxJ+t2vsK0WLDsAEm9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honggilgim/python_test_with_colab/blob/main/%EC%9D%91%EC%9A%A9%EC%88%98%ED%95%99_2022%EB%85%84_1%ED%95%99%EA%B8%B0_2016038005_%EA%B9%80%ED%99%8D%EA%B8%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnTGTTTcSW86"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import os\n",
        "\n",
        "train = pd.read_csv('/content/train2.csv')\n",
        "test = pd.read_csv('/content/test2.csv')\n",
        "\n",
        "train.drop('id', axis=1, inplace=True)\n",
        "test.drop('id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "FJ6Z2Ur6Fq8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상치 제거 - 데이터 이상치를 제거하여 학습 성능을 높임\n",
        "\n",
        "data_train = train.drop(index = [47, 382, 435, 847, 1078], axis = 0) # 전복무게 + 껍질무게 > 전체무게\n",
        "data_train = data_train.drop(index = [119, 129,179, 224, 290, 324, 346, 368, 374, 418, 430, 544, 599,\\\n",
        "                                      637, 692, 765, 794, 807, 817, 856, 922, 987, 989, 1013, 1020, \\\n",
        "                                      1035 ,1041, 1057, 1090, 1110, 1112], axis = 0) # 전체 무게 < (전복무게 + 내장무게 + 껍데기 무게) 인 경우(삭제)"
      ],
      "metadata": {
        "id": "Tw4benrJxalI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# foreign body column 추가, 전복 전체 무게 중 불필요한 물질들의 값.\n",
        "train_X = train.drop('Target', axis=1)\n",
        "train_y = train.Target\n",
        "\n",
        "train_X = pd.get_dummies(data = train_X, columns = ['Gender'], prefix = 'Gender')\n",
        "test = pd.get_dummies(data = test, columns = ['Gender'], prefix = 'Gender')\n",
        "\n",
        "foreign_body = train_X['Whole Weight'] - (train_X['Shucked Weight'] + train_X['Viscra Weight'] + train_X['Shell Weight'])\n",
        "train_X['foreign body'] = foreign_body\n",
        "train_X.loc[train_X['foreign body'] < 0 , 'foreign body'] = 0\n",
        "\n",
        "\n",
        "foreign_body = test['Whole Weight'] - (test['Shucked Weight'] + test['Viscra Weight'] + test['Shell Weight'])\n",
        "test['foreign body'] = foreign_body\n",
        "test.loc[test['foreign body'] < 0 , 'foreign body'] = 0"
      ],
      "metadata": {
        "id": "QOOewurwxmh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gender 데이터 분류 M/F인 데이터와 I인 데이터 분류\n",
        "train_X_MF=train_X[(train_X['Gender_F']==1) | (train_X['Gender_M']==1)]\n",
        "train_y_MF=train_y[(train_X['Gender_F']==1) | (train_X['Gender_M']==1)]\n",
        "train_X_I=train_X[train_X['Gender_I']==1]\n",
        "train_y_I=train_y[train_X['Gender_I']==1]\n",
        "\n",
        "test_MF=test[(test['Gender_F']==1) | (test['Gender_M']==1)]\n",
        "test_MF_idx=test_MF.index\n",
        "test_I=test[test['Gender_I']==1]\n",
        "test_I_idx=test_I.index\n",
        "\n",
        "train_X_MF.drop(['Gender_F', 'Gender_I', 'Gender_M'], axis=1, inplace=True)\n",
        "train_X_I.drop(['Gender_F', 'Gender_I', 'Gender_M'], axis=1, inplace=True)\n",
        "\n",
        "test_MF.drop(['Gender_F', 'Gender_I', 'Gender_M'], axis=1, inplace=True)\n",
        "test_I.drop(['Gender_F', 'Gender_I', 'Gender_M'], axis=1, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZwCXIclx0sh",
        "outputId": "013d3da9-7484-4011-8b76-7b3b88149b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### 여기부터, 학습 #######\n",
        "\"\"\"\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Osglui9bx7I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "temp=train_X\n",
        "temp['y']=train_y.values\n",
        "temp['Gender_MF']=temp['Gender_F']+temp['Gender_M']\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4bNQNyMBy_7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ntest_MF=test_MF.drop('Target', axis=1)"
      ],
      "metadata": {
        "id": "GSOSERkG2Cqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ntest_I=test_I.drop('Target', axis=1)"
      ],
      "metadata": {
        "id": "TPYw3lSH2Z29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "test_MF_data = pd.DataFrame(test_MF)\n",
        "test_MF_data.to_csv('test_MF.csv',index=False)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "obdiuQ-h6tzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for MIF in ['MF', 'I']:\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=9, activation='elu'))\n",
        "    model.add(Dense(32, activation='elu'))\n",
        "    model.add(Dense(64, activation='elu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='elu'))\n",
        "    model.add(Dense(16, activation='elu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(loss='mean_absolute_error',\n",
        "                  optimizer='Nadam',\n",
        "                  metrics=['mae'])\n",
        "\n",
        "\n",
        "    MODEL_DIR = './model_{0}/'.format(MIF)\n",
        "    if not os.path.exists(MODEL_DIR):\n",
        "        os.mkdir(MODEL_DIR)\n",
        "\n",
        "    temp='./model_' + MIF  + '/'\n",
        "    modelpath= temp + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
        "    #modelpath = './model_{0}/{epoch:02d}-{val_loss:.4f}.hdf5'.format(MIF)\n",
        "\n",
        "    # 모델 업데이트 및 저장\n",
        "    cp = ModelCheckpoint(filepath=modelpath, monitor='val_mae', verbose=0, save_best_only=True, mode = 'min')\n",
        "\n",
        "    # 학습 자동 중단 설정\n",
        "    es = EarlyStopping(monitor='val_mae', patience=50, mode='min')\n",
        "\n",
        "    rlrp = ReduceLROnPlateau(monitor='val_mae', factor=0.2, patience=40, mode='min')\n",
        "\n",
        "    # 모델 학습\n",
        "    if MIF=='MF':\n",
        "        model.fit(train_X_MF, train_y_MF, validation_split=0.3, epochs=1000, batch_size=32, verbose=1, callbacks=[es, cp, rlrp])\n",
        "        joblib.dump(model,'./2016038005_김홍길_MF.pkl')\n",
        "\n",
        "\n",
        "    elif MIF=='I':\n",
        "        model.fit(train_X_I, train_y_I, validation_split=0.3, epochs=1000, batch_size=32, verbose=1, callbacks=[es, cp, rlrp])\n",
        "        joblib.dump(model,'./2016038005_김홍길_I.pkl')\n",
        "\n",
        "\n",
        "####### 여기까지 학습 #######\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG7jDwEOyvx1",
        "outputId": "78194a19-49ba-471f-a722-50fbc96850cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "17/17 [==============================] - 1s 14ms/step - loss: 35.5400 - mae: 35.5400 - val_loss: 17.0070 - val_mae: 17.0070 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.1002 - mae: 17.1002 - val_loss: 9.3252 - val_mae: 9.3252 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.1556 - mae: 12.1556 - val_loss: 11.0798 - val_mae: 11.0798 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.5403 - mae: 9.5403 - val_loss: 7.5991 - val_mae: 7.5991 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 7.6507 - mae: 7.6507 - val_loss: 6.7181 - val_mae: 6.7181 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 7.3091 - mae: 7.3091 - val_loss: 5.5568 - val_mae: 5.5568 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 6.3671 - mae: 6.3671 - val_loss: 6.5658 - val_mae: 6.5658 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 6.5567 - mae: 6.5567 - val_loss: 5.7532 - val_mae: 5.7532 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5.7412 - mae: 5.7412 - val_loss: 5.9639 - val_mae: 5.9639 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.4098 - mae: 5.4098 - val_loss: 5.4864 - val_mae: 5.4864 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 5.1948 - mae: 5.1948 - val_loss: 5.3215 - val_mae: 5.3215 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.7536 - mae: 4.7536 - val_loss: 5.3031 - val_mae: 5.3031 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.3676 - mae: 4.3676 - val_loss: 5.0287 - val_mae: 5.0287 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 4.1041 - mae: 4.1041 - val_loss: 4.9221 - val_mae: 4.9221 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 3.8627 - mae: 3.8627 - val_loss: 3.5517 - val_mae: 3.5517 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.5525 - mae: 3.5525 - val_loss: 3.7873 - val_mae: 3.7873 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3.1218 - mae: 3.1218 - val_loss: 2.1969 - val_mae: 2.1969 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.9771 - mae: 2.9771 - val_loss: 2.2271 - val_mae: 2.2271 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0566 - mae: 3.0566 - val_loss: 2.2046 - val_mae: 2.2046 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0081 - mae: 3.0081 - val_loss: 2.4588 - val_mae: 2.4588 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.8437 - mae: 2.8437 - val_loss: 2.7638 - val_mae: 2.7638 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.8374 - mae: 2.8374 - val_loss: 2.2628 - val_mae: 2.2628 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 2.7665 - mae: 2.7665 - val_loss: 2.1028 - val_mae: 2.1028 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.8610 - mae: 2.8610 - val_loss: 2.2105 - val_mae: 2.2105 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6353 - mae: 2.6353 - val_loss: 2.2626 - val_mae: 2.2626 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.6706 - mae: 2.6706 - val_loss: 2.3152 - val_mae: 2.3152 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5862 - mae: 2.5862 - val_loss: 2.3463 - val_mae: 2.3463 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.6496 - mae: 2.6496 - val_loss: 2.5596 - val_mae: 2.5596 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.6235 - mae: 2.6235 - val_loss: 2.4718 - val_mae: 2.4718 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5401 - mae: 2.5401 - val_loss: 2.1876 - val_mae: 2.1876 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5521 - mae: 2.5521 - val_loss: 2.2526 - val_mae: 2.2526 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4498 - mae: 2.4498 - val_loss: 2.1373 - val_mae: 2.1373 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.5134 - mae: 2.5134 - val_loss: 2.1109 - val_mae: 2.1109 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.5357 - mae: 2.5357 - val_loss: 2.0958 - val_mae: 2.0958 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4928 - mae: 2.4928 - val_loss: 2.1582 - val_mae: 2.1582 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4437 - mae: 2.4437 - val_loss: 2.1051 - val_mae: 2.1051 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 2.5555 - mae: 2.5555 - val_loss: 2.0647 - val_mae: 2.0647 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.4434 - mae: 2.4434 - val_loss: 2.0645 - val_mae: 2.0645 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4902 - mae: 2.4902 - val_loss: 2.2164 - val_mae: 2.2164 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4085 - mae: 2.4085 - val_loss: 2.1685 - val_mae: 2.1685 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4558 - mae: 2.4558 - val_loss: 2.0743 - val_mae: 2.0743 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4269 - mae: 2.4269 - val_loss: 2.0649 - val_mae: 2.0649 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3883 - mae: 2.3883 - val_loss: 2.1182 - val_mae: 2.1182 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3654 - mae: 2.3654 - val_loss: 2.0895 - val_mae: 2.0895 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4598 - mae: 2.4598 - val_loss: 2.0718 - val_mae: 2.0718 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4647 - mae: 2.4647 - val_loss: 2.2143 - val_mae: 2.2143 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4372 - mae: 2.4372 - val_loss: 2.1009 - val_mae: 2.1009 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4301 - mae: 2.4301 - val_loss: 2.2595 - val_mae: 2.2595 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4473 - mae: 2.4473 - val_loss: 2.2507 - val_mae: 2.2507 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.3688 - mae: 2.3688 - val_loss: 2.1594 - val_mae: 2.1594 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3260 - mae: 2.3260 - val_loss: 2.1480 - val_mae: 2.1480 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3435 - mae: 2.3435 - val_loss: 2.0565 - val_mae: 2.0565 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3652 - mae: 2.3652 - val_loss: 2.0704 - val_mae: 2.0704 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.4010 - mae: 2.4010 - val_loss: 2.0918 - val_mae: 2.0918 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.3320 - mae: 2.3320 - val_loss: 2.0681 - val_mae: 2.0681 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3566 - mae: 2.3566 - val_loss: 2.0643 - val_mae: 2.0643 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3845 - mae: 2.3845 - val_loss: 2.0807 - val_mae: 2.0807 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3671 - mae: 2.3671 - val_loss: 2.2646 - val_mae: 2.2646 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4064 - mae: 2.4064 - val_loss: 2.0610 - val_mae: 2.0610 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3117 - mae: 2.3117 - val_loss: 2.2298 - val_mae: 2.2298 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3416 - mae: 2.3416 - val_loss: 2.1201 - val_mae: 2.1201 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3465 - mae: 2.3465 - val_loss: 2.2451 - val_mae: 2.2451 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3446 - mae: 2.3446 - val_loss: 2.0972 - val_mae: 2.0972 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3447 - mae: 2.3447 - val_loss: 2.1024 - val_mae: 2.1024 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3311 - mae: 2.3311 - val_loss: 2.1106 - val_mae: 2.1106 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3056 - mae: 2.3056 - val_loss: 2.1200 - val_mae: 2.1200 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3436 - mae: 2.3436 - val_loss: 2.1836 - val_mae: 2.1836 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3304 - mae: 2.3304 - val_loss: 2.0994 - val_mae: 2.0994 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3416 - mae: 2.3416 - val_loss: 2.0673 - val_mae: 2.0673 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3586 - mae: 2.3586 - val_loss: 2.1475 - val_mae: 2.1475 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2910 - mae: 2.2910 - val_loss: 2.1003 - val_mae: 2.1003 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3387 - mae: 2.3387 - val_loss: 2.3116 - val_mae: 2.3116 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3370 - mae: 2.3370 - val_loss: 2.1170 - val_mae: 2.1170 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3261 - mae: 2.3261 - val_loss: 2.0715 - val_mae: 2.0715 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3227 - mae: 2.3227 - val_loss: 2.0875 - val_mae: 2.0875 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3223 - mae: 2.3223 - val_loss: 2.0878 - val_mae: 2.0878 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3405 - mae: 2.3405 - val_loss: 2.0788 - val_mae: 2.0788 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2952 - mae: 2.2952 - val_loss: 2.0665 - val_mae: 2.0665 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3171 - mae: 2.3171 - val_loss: 2.0668 - val_mae: 2.0668 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2954 - mae: 2.2954 - val_loss: 2.0667 - val_mae: 2.0667 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2961 - mae: 2.2961 - val_loss: 2.0634 - val_mae: 2.0634 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2788 - mae: 2.2788 - val_loss: 2.0815 - val_mae: 2.0815 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2956 - mae: 2.2956 - val_loss: 2.1019 - val_mae: 2.1019 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3004 - mae: 2.3004 - val_loss: 2.1542 - val_mae: 2.1542 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2987 - mae: 2.2987 - val_loss: 2.0679 - val_mae: 2.0679 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2833 - mae: 2.2833 - val_loss: 2.1140 - val_mae: 2.1140 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3064 - mae: 2.3064 - val_loss: 2.1237 - val_mae: 2.1237 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2474 - mae: 2.2474 - val_loss: 2.0939 - val_mae: 2.0939 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2854 - mae: 2.2854 - val_loss: 2.0638 - val_mae: 2.0638 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2603 - mae: 2.2603 - val_loss: 2.0677 - val_mae: 2.0677 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.2675 - mae: 2.2675 - val_loss: 2.0946 - val_mae: 2.0946 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2944 - mae: 2.2944 - val_loss: 2.0837 - val_mae: 2.0837 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2.2623 - mae: 2.2623 - val_loss: 2.0732 - val_mae: 2.0732 - lr: 2.0000e-04\n",
            "Epoch 94/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2644 - mae: 2.2644 - val_loss: 2.0715 - val_mae: 2.0715 - lr: 2.0000e-04\n",
            "Epoch 95/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2500 - mae: 2.2500 - val_loss: 2.0730 - val_mae: 2.0730 - lr: 2.0000e-04\n",
            "Epoch 96/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2500 - mae: 2.2500 - val_loss: 2.0709 - val_mae: 2.0709 - lr: 2.0000e-04\n",
            "Epoch 97/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2679 - mae: 2.2679 - val_loss: 2.0930 - val_mae: 2.0930 - lr: 2.0000e-04\n",
            "Epoch 98/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2883 - mae: 2.2883 - val_loss: 2.0764 - val_mae: 2.0764 - lr: 2.0000e-04\n",
            "Epoch 99/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2862 - mae: 2.2862 - val_loss: 2.0720 - val_mae: 2.0720 - lr: 2.0000e-04\n",
            "Epoch 100/1000\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2601 - mae: 2.2601 - val_loss: 2.0776 - val_mae: 2.0776 - lr: 2.0000e-04\n",
            "Epoch 101/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2507 - mae: 2.2507 - val_loss: 2.0881 - val_mae: 2.0881 - lr: 2.0000e-04\n",
            "Epoch 102/1000\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2409 - mae: 2.2409 - val_loss: 2.0756 - val_mae: 2.0756 - lr: 2.0000e-04\n",
            "INFO:tensorflow:Assets written to: ram://39d9df45-7046-41f4-bb88-6a0cca9efce7/assets\n",
            "Epoch 1/1000\n",
            "8/8 [==============================] - 3s 31ms/step - loss: 19.5024 - mae: 19.5024 - val_loss: 18.4665 - val_mae: 18.4665 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 16.9838 - mae: 16.9838 - val_loss: 12.6007 - val_mae: 12.6007 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.9747 - mae: 13.9747 - val_loss: 12.9922 - val_mae: 12.9922 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 12.9061 - mae: 12.9061 - val_loss: 10.5158 - val_mae: 10.5158 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 10.5565 - mae: 10.5565 - val_loss: 4.6347 - val_mae: 4.6347 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.7327 - mae: 8.7327 - val_loss: 5.4622 - val_mae: 5.4622 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.7376 - mae: 7.7376 - val_loss: 5.4896 - val_mae: 5.4896 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0537 - mae: 7.0537 - val_loss: 5.9777 - val_mae: 5.9777 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.0931 - mae: 7.0931 - val_loss: 6.2629 - val_mae: 6.2629 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8978 - mae: 5.8978 - val_loss: 7.0280 - val_mae: 7.0280 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5466 - mae: 5.5466 - val_loss: 6.2775 - val_mae: 6.2775 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1699 - mae: 5.1699 - val_loss: 6.7291 - val_mae: 6.7291 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9434 - mae: 4.9434 - val_loss: 4.9516 - val_mae: 4.9516 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8267 - mae: 4.8267 - val_loss: 5.8604 - val_mae: 5.8604 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.5465 - mae: 4.5465 - val_loss: 4.8200 - val_mae: 4.8200 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.1316 - mae: 4.1316 - val_loss: 4.5934 - val_mae: 4.5934 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0465 - mae: 4.0465 - val_loss: 3.6174 - val_mae: 3.6174 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.6215 - mae: 3.6215 - val_loss: 3.7353 - val_mae: 3.7353 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.4059 - mae: 3.4059 - val_loss: 3.6956 - val_mae: 3.6956 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0876 - mae: 3.0876 - val_loss: 4.0389 - val_mae: 4.0389 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1919 - mae: 3.1919 - val_loss: 3.8412 - val_mae: 3.8412 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 3.0098 - mae: 3.0098 - val_loss: 3.5433 - val_mae: 3.5433 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.5861 - mae: 2.5861 - val_loss: 2.6642 - val_mae: 2.6642 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.6891 - mae: 2.6891 - val_loss: 2.4191 - val_mae: 2.4191 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.6518 - mae: 2.6518 - val_loss: 2.4336 - val_mae: 2.4336 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.6870 - mae: 2.6870 - val_loss: 3.1353 - val_mae: 3.1353 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.4397 - mae: 2.4397 - val_loss: 3.4478 - val_mae: 3.4478 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.4152 - mae: 2.4152 - val_loss: 3.5727 - val_mae: 3.5727 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3064 - mae: 2.3064 - val_loss: 2.4811 - val_mae: 2.4811 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.4431 - mae: 2.4431 - val_loss: 2.9204 - val_mae: 2.9204 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.3500 - mae: 2.3500 - val_loss: 2.8432 - val_mae: 2.8432 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.3325 - mae: 2.3325 - val_loss: 2.5333 - val_mae: 2.5333 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0763 - mae: 2.0763 - val_loss: 2.5253 - val_mae: 2.5253 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.3148 - mae: 2.3148 - val_loss: 2.3475 - val_mae: 2.3475 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.3132 - mae: 2.3132 - val_loss: 2.4138 - val_mae: 2.4138 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.0755 - mae: 2.0755 - val_loss: 2.2834 - val_mae: 2.2834 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.2504 - mae: 2.2504 - val_loss: 2.2642 - val_mae: 2.2642 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.2499 - mae: 2.2499 - val_loss: 2.2323 - val_mae: 2.2323 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.1858 - mae: 2.1858 - val_loss: 2.1939 - val_mae: 2.1939 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.1212 - mae: 2.1212 - val_loss: 2.1816 - val_mae: 2.1816 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1024 - mae: 2.1024 - val_loss: 2.2962 - val_mae: 2.2962 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 2.1314 - mae: 2.1314 - val_loss: 2.0979 - val_mae: 2.0979 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0787 - mae: 2.0787 - val_loss: 2.2606 - val_mae: 2.2606 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2606 - mae: 2.2606 - val_loss: 2.3422 - val_mae: 2.3422 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0465 - mae: 2.0465 - val_loss: 2.4572 - val_mae: 2.4572 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0540 - mae: 2.0540 - val_loss: 2.2226 - val_mae: 2.2226 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1980 - mae: 2.1980 - val_loss: 2.2680 - val_mae: 2.2680 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1914 - mae: 2.1914 - val_loss: 2.2459 - val_mae: 2.2459 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0061 - mae: 2.0061 - val_loss: 2.3132 - val_mae: 2.3132 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.1243 - mae: 2.1243 - val_loss: 2.2024 - val_mae: 2.2024 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1381 - mae: 2.1381 - val_loss: 2.2751 - val_mae: 2.2751 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0252 - mae: 2.0252 - val_loss: 2.1150 - val_mae: 2.1150 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0140 - mae: 2.0140 - val_loss: 2.2494 - val_mae: 2.2494 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9514 - mae: 1.9514 - val_loss: 2.2134 - val_mae: 2.2134 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0183 - mae: 2.0183 - val_loss: 2.3154 - val_mae: 2.3154 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0744 - mae: 2.0744 - val_loss: 2.1524 - val_mae: 2.1524 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.0801 - mae: 2.0801 - val_loss: 2.2408 - val_mae: 2.2408 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.1696 - mae: 2.1696 - val_loss: 2.2580 - val_mae: 2.2580 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9695 - mae: 1.9695 - val_loss: 2.1026 - val_mae: 2.1026 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.2462 - mae: 2.2462 - val_loss: 2.2302 - val_mae: 2.2302 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0254 - mae: 2.0254 - val_loss: 2.2882 - val_mae: 2.2882 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0559 - mae: 2.0559 - val_loss: 2.2973 - val_mae: 2.2973 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0241 - mae: 2.0241 - val_loss: 2.2881 - val_mae: 2.2881 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0401 - mae: 2.0401 - val_loss: 2.2781 - val_mae: 2.2781 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9796 - mae: 1.9796 - val_loss: 2.2384 - val_mae: 2.2384 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9882 - mae: 1.9882 - val_loss: 2.1226 - val_mae: 2.1226 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8774 - mae: 1.8774 - val_loss: 2.2887 - val_mae: 2.2887 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9520 - mae: 1.9520 - val_loss: 2.2009 - val_mae: 2.2009 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0624 - mae: 2.0624 - val_loss: 2.2976 - val_mae: 2.2976 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9031 - mae: 1.9031 - val_loss: 2.2135 - val_mae: 2.2135 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8750 - mae: 1.8750 - val_loss: 2.1546 - val_mae: 2.1546 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9623 - mae: 1.9623 - val_loss: 2.3260 - val_mae: 2.3260 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0843 - mae: 2.0843 - val_loss: 2.2002 - val_mae: 2.2002 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9675 - mae: 1.9675 - val_loss: 2.1476 - val_mae: 2.1476 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.8327 - mae: 1.8327 - val_loss: 2.0022 - val_mae: 2.0022 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.8875 - mae: 1.8875 - val_loss: 1.9850 - val_mae: 1.9850 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9182 - mae: 1.9182 - val_loss: 2.0168 - val_mae: 2.0168 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9437 - mae: 1.9437 - val_loss: 2.0074 - val_mae: 2.0074 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9457 - mae: 1.9457 - val_loss: 2.1821 - val_mae: 2.1821 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8429 - mae: 1.8429 - val_loss: 2.0515 - val_mae: 2.0515 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9037 - mae: 1.9037 - val_loss: 2.2856 - val_mae: 2.2856 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8897 - mae: 1.8897 - val_loss: 2.1906 - val_mae: 2.1906 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1349 - mae: 2.1349 - val_loss: 2.1745 - val_mae: 2.1745 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.9067 - mae: 1.9067 - val_loss: 2.0706 - val_mae: 2.0706 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8757 - mae: 1.8757 - val_loss: 2.1931 - val_mae: 2.1931 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9431 - mae: 1.9431 - val_loss: 2.2541 - val_mae: 2.2541 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8325 - mae: 1.8325 - val_loss: 2.1242 - val_mae: 2.1242 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8764 - mae: 1.8764 - val_loss: 2.2651 - val_mae: 2.2651 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7797 - mae: 1.7797 - val_loss: 2.1127 - val_mae: 2.1127 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.8128 - mae: 1.8128 - val_loss: 2.2106 - val_mae: 2.2106 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8925 - mae: 1.8925 - val_loss: 2.1979 - val_mae: 2.1979 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9185 - mae: 1.9185 - val_loss: 2.1722 - val_mae: 2.1722 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.9750 - mae: 1.9750 - val_loss: 2.1017 - val_mae: 2.1017 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8546 - mae: 1.8546 - val_loss: 2.1122 - val_mae: 2.1122 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8471 - mae: 1.8471 - val_loss: 2.2159 - val_mae: 2.2159 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.7940 - mae: 1.7940 - val_loss: 1.9775 - val_mae: 1.9775 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.8106 - mae: 1.8106 - val_loss: 2.1443 - val_mae: 2.1443 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8803 - mae: 1.8803 - val_loss: 2.0356 - val_mae: 2.0356 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8474 - mae: 1.8474 - val_loss: 2.0179 - val_mae: 2.0179 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7761 - mae: 1.7761 - val_loss: 2.0942 - val_mae: 2.0942 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8833 - mae: 1.8833 - val_loss: 2.0614 - val_mae: 2.0614 - lr: 0.0010\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7823 - mae: 1.7823 - val_loss: 2.1447 - val_mae: 2.1447 - lr: 0.0010\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0085 - mae: 2.0085 - val_loss: 2.1131 - val_mae: 2.1131 - lr: 0.0010\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8694 - mae: 1.8694 - val_loss: 2.0597 - val_mae: 2.0597 - lr: 0.0010\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8139 - mae: 1.8139 - val_loss: 3.0496 - val_mae: 3.0496 - lr: 0.0010\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.2341 - mae: 2.2341 - val_loss: 2.1435 - val_mae: 2.1435 - lr: 0.0010\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.9046 - mae: 1.9046 - val_loss: 1.9925 - val_mae: 1.9925 - lr: 0.0010\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8034 - mae: 1.8034 - val_loss: 1.9856 - val_mae: 1.9856 - lr: 0.0010\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8622 - mae: 1.8622 - val_loss: 1.9820 - val_mae: 1.9820 - lr: 0.0010\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.8038 - mae: 1.8038 - val_loss: 1.9431 - val_mae: 1.9431 - lr: 0.0010\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8458 - mae: 1.8458 - val_loss: 1.9707 - val_mae: 1.9707 - lr: 0.0010\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8143 - mae: 1.8143 - val_loss: 1.9567 - val_mae: 1.9567 - lr: 0.0010\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.9752 - mae: 1.9752 - val_loss: 2.0003 - val_mae: 2.0003 - lr: 0.0010\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8840 - mae: 1.8840 - val_loss: 1.9527 - val_mae: 1.9527 - lr: 0.0010\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9978 - mae: 1.9978 - val_loss: 1.9889 - val_mae: 1.9889 - lr: 0.0010\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9882 - mae: 1.9882 - val_loss: 2.0336 - val_mae: 2.0336 - lr: 0.0010\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8565 - mae: 1.8565 - val_loss: 1.9802 - val_mae: 1.9802 - lr: 0.0010\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8539 - mae: 1.8539 - val_loss: 2.0192 - val_mae: 2.0192 - lr: 0.0010\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7840 - mae: 1.7840 - val_loss: 1.9662 - val_mae: 1.9662 - lr: 0.0010\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7527 - mae: 1.7527 - val_loss: 2.0208 - val_mae: 2.0208 - lr: 0.0010\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7345 - mae: 1.7345 - val_loss: 1.9896 - val_mae: 1.9896 - lr: 0.0010\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7818 - mae: 1.7818 - val_loss: 1.9763 - val_mae: 1.9763 - lr: 0.0010\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8142 - mae: 1.8142 - val_loss: 1.9881 - val_mae: 1.9881 - lr: 0.0010\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7475 - mae: 1.7475 - val_loss: 2.0229 - val_mae: 2.0229 - lr: 0.0010\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7580 - mae: 1.7580 - val_loss: 2.1337 - val_mae: 2.1337 - lr: 0.0010\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9779 - mae: 1.9779 - val_loss: 1.9695 - val_mae: 1.9695 - lr: 0.0010\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8353 - mae: 1.8353 - val_loss: 2.0978 - val_mae: 2.0978 - lr: 0.0010\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7302 - mae: 1.7302 - val_loss: 2.1572 - val_mae: 2.1572 - lr: 0.0010\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8671 - mae: 1.8671 - val_loss: 2.0246 - val_mae: 2.0246 - lr: 0.0010\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7589 - mae: 1.7589 - val_loss: 1.9532 - val_mae: 1.9532 - lr: 0.0010\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7483 - mae: 1.7483 - val_loss: 1.9593 - val_mae: 1.9593 - lr: 0.0010\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.8021 - mae: 1.8021 - val_loss: 1.9794 - val_mae: 1.9794 - lr: 0.0010\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8040 - mae: 1.8040 - val_loss: 1.9253 - val_mae: 1.9253 - lr: 0.0010\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7014 - mae: 1.7014 - val_loss: 1.9681 - val_mae: 1.9681 - lr: 0.0010\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7517 - mae: 1.7517 - val_loss: 1.9869 - val_mae: 1.9869 - lr: 0.0010\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7173 - mae: 1.7173 - val_loss: 2.0770 - val_mae: 2.0770 - lr: 0.0010\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6348 - mae: 1.6348 - val_loss: 1.9511 - val_mae: 1.9511 - lr: 0.0010\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7398 - mae: 1.7398 - val_loss: 1.9782 - val_mae: 1.9782 - lr: 0.0010\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.6681 - mae: 1.6681 - val_loss: 1.9753 - val_mae: 1.9753 - lr: 0.0010\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7250 - mae: 1.7250 - val_loss: 2.0568 - val_mae: 2.0568 - lr: 0.0010\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7963 - mae: 1.7963 - val_loss: 1.9871 - val_mae: 1.9871 - lr: 0.0010\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7529 - mae: 1.7529 - val_loss: 1.9540 - val_mae: 1.9540 - lr: 0.0010\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7098 - mae: 1.7098 - val_loss: 2.0003 - val_mae: 2.0003 - lr: 0.0010\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7609 - mae: 1.7609 - val_loss: 1.9580 - val_mae: 1.9580 - lr: 0.0010\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.6962 - mae: 1.6962 - val_loss: 1.9412 - val_mae: 1.9412 - lr: 0.0010\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6914 - mae: 1.6914 - val_loss: 1.9599 - val_mae: 1.9599 - lr: 0.0010\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.6593 - mae: 1.6593 - val_loss: 1.8885 - val_mae: 1.8885 - lr: 0.0010\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.8401 - mae: 1.8401 - val_loss: 1.8854 - val_mae: 1.8854 - lr: 0.0010\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.7543 - mae: 1.7543 - val_loss: 1.8585 - val_mae: 1.8585 - lr: 0.0010\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7935 - mae: 1.7935 - val_loss: 1.9532 - val_mae: 1.9532 - lr: 0.0010\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7021 - mae: 1.7021 - val_loss: 1.8816 - val_mae: 1.8816 - lr: 0.0010\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6733 - mae: 1.6733 - val_loss: 1.9753 - val_mae: 1.9753 - lr: 0.0010\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7267 - mae: 1.7267 - val_loss: 2.0489 - val_mae: 2.0489 - lr: 0.0010\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7539 - mae: 1.7539 - val_loss: 1.9118 - val_mae: 1.9118 - lr: 0.0010\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7579 - mae: 1.7579 - val_loss: 1.9499 - val_mae: 1.9499 - lr: 0.0010\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7107 - mae: 1.7107 - val_loss: 1.8847 - val_mae: 1.8847 - lr: 0.0010\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.9443 - mae: 1.9443 - val_loss: 1.8884 - val_mae: 1.8884 - lr: 0.0010\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7288 - mae: 1.7288 - val_loss: 1.9276 - val_mae: 1.9276 - lr: 0.0010\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7777 - mae: 1.7777 - val_loss: 1.9793 - val_mae: 1.9793 - lr: 0.0010\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7313 - mae: 1.7313 - val_loss: 1.9172 - val_mae: 1.9172 - lr: 0.0010\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7260 - mae: 1.7260 - val_loss: 1.9511 - val_mae: 1.9511 - lr: 0.0010\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7599 - mae: 1.7599 - val_loss: 1.9884 - val_mae: 1.9884 - lr: 0.0010\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7422 - mae: 1.7422 - val_loss: 1.9043 - val_mae: 1.9043 - lr: 0.0010\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7413 - mae: 1.7413 - val_loss: 1.9627 - val_mae: 1.9627 - lr: 0.0010\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7706 - mae: 1.7706 - val_loss: 1.9209 - val_mae: 1.9209 - lr: 0.0010\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7402 - mae: 1.7402 - val_loss: 1.9919 - val_mae: 1.9919 - lr: 0.0010\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5973 - mae: 1.5973 - val_loss: 1.8697 - val_mae: 1.8697 - lr: 0.0010\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6479 - mae: 1.6479 - val_loss: 1.8889 - val_mae: 1.8889 - lr: 0.0010\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6825 - mae: 1.6825 - val_loss: 1.9536 - val_mae: 1.9536 - lr: 0.0010\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6967 - mae: 1.6967 - val_loss: 1.8911 - val_mae: 1.8911 - lr: 0.0010\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6475 - mae: 1.6475 - val_loss: 1.9648 - val_mae: 1.9648 - lr: 0.0010\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7009 - mae: 1.7009 - val_loss: 1.9221 - val_mae: 1.9221 - lr: 0.0010\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.8361 - mae: 1.8361 - val_loss: 2.0248 - val_mae: 2.0248 - lr: 0.0010\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7367 - mae: 1.7367 - val_loss: 1.9469 - val_mae: 1.9469 - lr: 0.0010\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6973 - mae: 1.6973 - val_loss: 1.9833 - val_mae: 1.9833 - lr: 0.0010\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7462 - mae: 1.7462 - val_loss: 2.0040 - val_mae: 2.0040 - lr: 0.0010\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7791 - mae: 1.7791 - val_loss: 1.9142 - val_mae: 1.9142 - lr: 0.0010\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7403 - mae: 1.7403 - val_loss: 1.9653 - val_mae: 1.9653 - lr: 0.0010\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.6648 - mae: 1.6648 - val_loss: 1.9865 - val_mae: 1.9865 - lr: 0.0010\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.6965 - mae: 1.6965 - val_loss: 1.9384 - val_mae: 1.9384 - lr: 0.0010\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.7291 - mae: 1.7291 - val_loss: 1.8801 - val_mae: 1.8801 - lr: 0.0010\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.7379 - mae: 1.7379 - val_loss: 1.9737 - val_mae: 1.9737 - lr: 0.0010\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6883 - mae: 1.6883 - val_loss: 1.9470 - val_mae: 1.9470 - lr: 0.0010\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.7143 - mae: 1.7143 - val_loss: 1.9104 - val_mae: 1.9104 - lr: 0.0010\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6888 - mae: 1.6888 - val_loss: 1.9066 - val_mae: 1.9066 - lr: 0.0010\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.6708 - mae: 1.6708 - val_loss: 2.1360 - val_mae: 2.1360 - lr: 0.0010\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6841 - mae: 1.6841 - val_loss: 1.9602 - val_mae: 1.9602 - lr: 0.0010\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5992 - mae: 1.5992 - val_loss: 1.8904 - val_mae: 1.8904 - lr: 0.0010\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.6144 - mae: 1.6144 - val_loss: 1.8897 - val_mae: 1.8897 - lr: 0.0010\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.6270 - mae: 1.6270 - val_loss: 1.8166 - val_mae: 1.8166 - lr: 2.0000e-04\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.5516 - mae: 1.5516 - val_loss: 1.8451 - val_mae: 1.8451 - lr: 2.0000e-04\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.5218 - mae: 1.5218 - val_loss: 1.7932 - val_mae: 1.7932 - lr: 2.0000e-04\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.5032 - mae: 1.5032 - val_loss: 1.7797 - val_mae: 1.7797 - lr: 2.0000e-04\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.5348 - mae: 1.5348 - val_loss: 1.7637 - val_mae: 1.7637 - lr: 2.0000e-04\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5367 - mae: 1.5367 - val_loss: 1.7783 - val_mae: 1.7783 - lr: 2.0000e-04\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.5093 - mae: 1.5093 - val_loss: 1.7148 - val_mae: 1.7148 - lr: 2.0000e-04\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.5062 - mae: 1.5062 - val_loss: 1.7010 - val_mae: 1.7010 - lr: 2.0000e-04\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4786 - mae: 1.4786 - val_loss: 1.8110 - val_mae: 1.8110 - lr: 2.0000e-04\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4576 - mae: 1.4576 - val_loss: 1.7879 - val_mae: 1.7879 - lr: 2.0000e-04\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4375 - mae: 1.4375 - val_loss: 1.6885 - val_mae: 1.6885 - lr: 2.0000e-04\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4245 - mae: 1.4245 - val_loss: 1.7439 - val_mae: 1.7439 - lr: 2.0000e-04\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4655 - mae: 1.4655 - val_loss: 1.7391 - val_mae: 1.7391 - lr: 2.0000e-04\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4677 - mae: 1.4677 - val_loss: 1.7570 - val_mae: 1.7570 - lr: 2.0000e-04\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4149 - mae: 1.4149 - val_loss: 1.6740 - val_mae: 1.6740 - lr: 2.0000e-04\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4526 - mae: 1.4526 - val_loss: 1.6870 - val_mae: 1.6870 - lr: 2.0000e-04\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4371 - mae: 1.4371 - val_loss: 1.6965 - val_mae: 1.6965 - lr: 2.0000e-04\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4231 - mae: 1.4231 - val_loss: 1.6879 - val_mae: 1.6879 - lr: 2.0000e-04\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4617 - mae: 1.4617 - val_loss: 1.6845 - val_mae: 1.6845 - lr: 2.0000e-04\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3607 - mae: 1.3607 - val_loss: 1.7987 - val_mae: 1.7987 - lr: 2.0000e-04\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4476 - mae: 1.4476 - val_loss: 1.7427 - val_mae: 1.7427 - lr: 2.0000e-04\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4014 - mae: 1.4014 - val_loss: 1.7326 - val_mae: 1.7326 - lr: 2.0000e-04\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3970 - mae: 1.3970 - val_loss: 1.7775 - val_mae: 1.7775 - lr: 2.0000e-04\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3198 - mae: 1.3198 - val_loss: 1.7277 - val_mae: 1.7277 - lr: 2.0000e-04\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2677 - mae: 1.2677 - val_loss: 1.7882 - val_mae: 1.7882 - lr: 2.0000e-04\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4336 - mae: 1.4336 - val_loss: 1.6716 - val_mae: 1.6716 - lr: 2.0000e-04\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4174 - mae: 1.4174 - val_loss: 1.6098 - val_mae: 1.6098 - lr: 2.0000e-04\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3840 - mae: 1.3840 - val_loss: 1.6217 - val_mae: 1.6217 - lr: 2.0000e-04\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4078 - mae: 1.4078 - val_loss: 1.6388 - val_mae: 1.6388 - lr: 2.0000e-04\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3821 - mae: 1.3821 - val_loss: 1.6152 - val_mae: 1.6152 - lr: 2.0000e-04\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2920 - mae: 1.2920 - val_loss: 1.5777 - val_mae: 1.5777 - lr: 2.0000e-04\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3142 - mae: 1.3142 - val_loss: 1.6870 - val_mae: 1.6870 - lr: 2.0000e-04\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4032 - mae: 1.4032 - val_loss: 1.6316 - val_mae: 1.6316 - lr: 2.0000e-04\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3810 - mae: 1.3810 - val_loss: 1.6096 - val_mae: 1.6096 - lr: 2.0000e-04\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2814 - mae: 1.2814 - val_loss: 1.6237 - val_mae: 1.6237 - lr: 2.0000e-04\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3803 - mae: 1.3803 - val_loss: 1.5782 - val_mae: 1.5782 - lr: 2.0000e-04\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3668 - mae: 1.3668 - val_loss: 1.7609 - val_mae: 1.7609 - lr: 2.0000e-04\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3760 - mae: 1.3760 - val_loss: 1.6593 - val_mae: 1.6593 - lr: 2.0000e-04\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3601 - mae: 1.3601 - val_loss: 1.6532 - val_mae: 1.6532 - lr: 2.0000e-04\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3369 - mae: 1.3369 - val_loss: 1.6281 - val_mae: 1.6281 - lr: 2.0000e-04\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4092 - mae: 1.4092 - val_loss: 1.5974 - val_mae: 1.5974 - lr: 2.0000e-04\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3639 - mae: 1.3639 - val_loss: 1.6821 - val_mae: 1.6821 - lr: 2.0000e-04\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3161 - mae: 1.3161 - val_loss: 1.6613 - val_mae: 1.6613 - lr: 2.0000e-04\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3736 - mae: 1.3736 - val_loss: 1.5835 - val_mae: 1.5835 - lr: 2.0000e-04\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3346 - mae: 1.3346 - val_loss: 1.6991 - val_mae: 1.6991 - lr: 2.0000e-04\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3666 - mae: 1.3666 - val_loss: 1.7106 - val_mae: 1.7106 - lr: 2.0000e-04\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3146 - mae: 1.3146 - val_loss: 1.6496 - val_mae: 1.6496 - lr: 2.0000e-04\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.3344 - mae: 1.3344 - val_loss: 1.5760 - val_mae: 1.5760 - lr: 2.0000e-04\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3657 - mae: 1.3657 - val_loss: 1.7024 - val_mae: 1.7024 - lr: 2.0000e-04\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3268 - mae: 1.3268 - val_loss: 1.6637 - val_mae: 1.6637 - lr: 2.0000e-04\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3701 - mae: 1.3701 - val_loss: 1.6119 - val_mae: 1.6119 - lr: 2.0000e-04\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2967 - mae: 1.2967 - val_loss: 1.6908 - val_mae: 1.6908 - lr: 2.0000e-04\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3275 - mae: 1.3275 - val_loss: 1.7366 - val_mae: 1.7366 - lr: 2.0000e-04\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2517 - mae: 1.2517 - val_loss: 1.5771 - val_mae: 1.5771 - lr: 2.0000e-04\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.3153 - mae: 1.3153 - val_loss: 1.5727 - val_mae: 1.5727 - lr: 2.0000e-04\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3403 - mae: 1.3403 - val_loss: 1.5753 - val_mae: 1.5753 - lr: 2.0000e-04\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2818 - mae: 1.2818 - val_loss: 1.7144 - val_mae: 1.7144 - lr: 2.0000e-04\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3087 - mae: 1.3087 - val_loss: 1.6657 - val_mae: 1.6657 - lr: 2.0000e-04\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3542 - mae: 1.3542 - val_loss: 1.5510 - val_mae: 1.5510 - lr: 2.0000e-04\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2866 - mae: 1.2866 - val_loss: 1.5636 - val_mae: 1.5636 - lr: 2.0000e-04\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3537 - mae: 1.3537 - val_loss: 1.7818 - val_mae: 1.7818 - lr: 2.0000e-04\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3096 - mae: 1.3096 - val_loss: 1.5929 - val_mae: 1.5929 - lr: 2.0000e-04\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3549 - mae: 1.3549 - val_loss: 1.5683 - val_mae: 1.5683 - lr: 2.0000e-04\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2559 - mae: 1.2559 - val_loss: 1.5384 - val_mae: 1.5384 - lr: 2.0000e-04\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3817 - mae: 1.3817 - val_loss: 1.6631 - val_mae: 1.6631 - lr: 2.0000e-04\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3364 - mae: 1.3364 - val_loss: 1.6101 - val_mae: 1.6101 - lr: 2.0000e-04\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2651 - mae: 1.2651 - val_loss: 1.5503 - val_mae: 1.5503 - lr: 2.0000e-04\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2944 - mae: 1.2944 - val_loss: 1.5735 - val_mae: 1.5735 - lr: 2.0000e-04\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2489 - mae: 1.2489 - val_loss: 1.6072 - val_mae: 1.6072 - lr: 2.0000e-04\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2790 - mae: 1.2790 - val_loss: 1.5723 - val_mae: 1.5723 - lr: 2.0000e-04\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2545 - mae: 1.2545 - val_loss: 1.5677 - val_mae: 1.5677 - lr: 2.0000e-04\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3329 - mae: 1.3329 - val_loss: 1.6244 - val_mae: 1.6244 - lr: 2.0000e-04\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3312 - mae: 1.3312 - val_loss: 1.5609 - val_mae: 1.5609 - lr: 2.0000e-04\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3021 - mae: 1.3021 - val_loss: 1.5974 - val_mae: 1.5974 - lr: 2.0000e-04\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2565 - mae: 1.2565 - val_loss: 1.5943 - val_mae: 1.5943 - lr: 2.0000e-04\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3025 - mae: 1.3025 - val_loss: 1.5832 - val_mae: 1.5832 - lr: 2.0000e-04\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3174 - mae: 1.3174 - val_loss: 1.5532 - val_mae: 1.5532 - lr: 2.0000e-04\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2401 - mae: 1.2401 - val_loss: 1.6401 - val_mae: 1.6401 - lr: 2.0000e-04\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2211 - mae: 1.2211 - val_loss: 1.5692 - val_mae: 1.5692 - lr: 2.0000e-04\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2447 - mae: 1.2447 - val_loss: 1.6477 - val_mae: 1.6477 - lr: 2.0000e-04\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3570 - mae: 1.3570 - val_loss: 1.5904 - val_mae: 1.5904 - lr: 2.0000e-04\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2823 - mae: 1.2823 - val_loss: 1.5734 - val_mae: 1.5734 - lr: 2.0000e-04\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3208 - mae: 1.3208 - val_loss: 1.8654 - val_mae: 1.8654 - lr: 2.0000e-04\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3586 - mae: 1.3586 - val_loss: 1.5610 - val_mae: 1.5610 - lr: 2.0000e-04\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2890 - mae: 1.2890 - val_loss: 1.5355 - val_mae: 1.5355 - lr: 2.0000e-04\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.2084 - mae: 1.2084 - val_loss: 1.5286 - val_mae: 1.5286 - lr: 2.0000e-04\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.3211 - mae: 1.3211 - val_loss: 1.5481 - val_mae: 1.5481 - lr: 2.0000e-04\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2819 - mae: 1.2819 - val_loss: 1.5535 - val_mae: 1.5535 - lr: 2.0000e-04\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3509 - mae: 1.3509 - val_loss: 1.7010 - val_mae: 1.7010 - lr: 2.0000e-04\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3184 - mae: 1.3184 - val_loss: 1.6075 - val_mae: 1.6075 - lr: 2.0000e-04\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2843 - mae: 1.2843 - val_loss: 1.5623 - val_mae: 1.5623 - lr: 2.0000e-04\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.2509 - mae: 1.2509 - val_loss: 1.5266 - val_mae: 1.5266 - lr: 2.0000e-04\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.3149 - mae: 1.3149 - val_loss: 1.5683 - val_mae: 1.5683 - lr: 2.0000e-04\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2672 - mae: 1.2672 - val_loss: 1.8558 - val_mae: 1.8558 - lr: 2.0000e-04\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2489 - mae: 1.2489 - val_loss: 1.5336 - val_mae: 1.5336 - lr: 2.0000e-04\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2888 - mae: 1.2888 - val_loss: 1.7104 - val_mae: 1.7104 - lr: 2.0000e-04\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2700 - mae: 1.2700 - val_loss: 1.6581 - val_mae: 1.6581 - lr: 2.0000e-04\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1978 - mae: 1.1978 - val_loss: 1.5431 - val_mae: 1.5431 - lr: 2.0000e-04\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2710 - mae: 1.2710 - val_loss: 1.5256 - val_mae: 1.5256 - lr: 2.0000e-04\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2737 - mae: 1.2737 - val_loss: 1.6627 - val_mae: 1.6627 - lr: 2.0000e-04\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2596 - mae: 1.2596 - val_loss: 1.5637 - val_mae: 1.5637 - lr: 2.0000e-04\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2817 - mae: 1.2817 - val_loss: 1.5979 - val_mae: 1.5979 - lr: 2.0000e-04\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2984 - mae: 1.2984 - val_loss: 1.5779 - val_mae: 1.5779 - lr: 2.0000e-04\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1754 - mae: 1.1754 - val_loss: 1.5357 - val_mae: 1.5357 - lr: 2.0000e-04\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1463 - mae: 1.1463 - val_loss: 1.5351 - val_mae: 1.5351 - lr: 2.0000e-04\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3005 - mae: 1.3005 - val_loss: 1.6363 - val_mae: 1.6363 - lr: 2.0000e-04\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2289 - mae: 1.2289 - val_loss: 1.5669 - val_mae: 1.5669 - lr: 2.0000e-04\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1953 - mae: 1.1953 - val_loss: 1.5341 - val_mae: 1.5341 - lr: 2.0000e-04\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2510 - mae: 1.2510 - val_loss: 1.5817 - val_mae: 1.5817 - lr: 2.0000e-04\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2732 - mae: 1.2732 - val_loss: 1.6286 - val_mae: 1.6286 - lr: 2.0000e-04\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2279 - mae: 1.2279 - val_loss: 1.6271 - val_mae: 1.6271 - lr: 2.0000e-04\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2625 - mae: 1.2625 - val_loss: 1.5435 - val_mae: 1.5435 - lr: 2.0000e-04\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2679 - mae: 1.2679 - val_loss: 1.5386 - val_mae: 1.5386 - lr: 2.0000e-04\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2941 - mae: 1.2941 - val_loss: 1.5331 - val_mae: 1.5331 - lr: 2.0000e-04\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2964 - mae: 1.2964 - val_loss: 1.7851 - val_mae: 1.7851 - lr: 2.0000e-04\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2159 - mae: 1.2159 - val_loss: 1.5849 - val_mae: 1.5849 - lr: 2.0000e-04\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2703 - mae: 1.2703 - val_loss: 1.5379 - val_mae: 1.5379 - lr: 2.0000e-04\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.2698 - mae: 1.2698 - val_loss: 1.5199 - val_mae: 1.5199 - lr: 2.0000e-04\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2298 - mae: 1.2298 - val_loss: 1.6563 - val_mae: 1.6563 - lr: 2.0000e-04\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2225 - mae: 1.2225 - val_loss: 1.6449 - val_mae: 1.6449 - lr: 2.0000e-04\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1660 - mae: 1.1660 - val_loss: 1.6350 - val_mae: 1.6350 - lr: 2.0000e-04\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2220 - mae: 1.2220 - val_loss: 1.6481 - val_mae: 1.6481 - lr: 2.0000e-04\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2288 - mae: 1.2288 - val_loss: 1.5199 - val_mae: 1.5199 - lr: 2.0000e-04\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.2707 - mae: 1.2707 - val_loss: 1.5192 - val_mae: 1.5192 - lr: 2.0000e-04\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2224 - mae: 1.2224 - val_loss: 1.5377 - val_mae: 1.5377 - lr: 2.0000e-04\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2139 - mae: 1.2139 - val_loss: 1.5675 - val_mae: 1.5675 - lr: 2.0000e-04\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2456 - mae: 1.2456 - val_loss: 1.5659 - val_mae: 1.5659 - lr: 2.0000e-04\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2963 - mae: 1.2963 - val_loss: 1.6279 - val_mae: 1.6279 - lr: 2.0000e-04\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2913 - mae: 1.2913 - val_loss: 1.5293 - val_mae: 1.5293 - lr: 2.0000e-04\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2743 - mae: 1.2743 - val_loss: 1.5741 - val_mae: 1.5741 - lr: 2.0000e-04\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2872 - mae: 1.2872 - val_loss: 1.5282 - val_mae: 1.5282 - lr: 2.0000e-04\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1686 - mae: 1.1686 - val_loss: 1.5885 - val_mae: 1.5885 - lr: 2.0000e-04\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1828 - mae: 1.1828 - val_loss: 1.5500 - val_mae: 1.5500 - lr: 2.0000e-04\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2615 - mae: 1.2615 - val_loss: 1.5714 - val_mae: 1.5714 - lr: 2.0000e-04\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1561 - mae: 1.1561 - val_loss: 1.5318 - val_mae: 1.5318 - lr: 2.0000e-04\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2700 - mae: 1.2700 - val_loss: 1.5396 - val_mae: 1.5396 - lr: 2.0000e-04\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1525 - mae: 1.1525 - val_loss: 1.5168 - val_mae: 1.5168 - lr: 2.0000e-04\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3192 - mae: 1.3192 - val_loss: 1.5486 - val_mae: 1.5486 - lr: 2.0000e-04\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2314 - mae: 1.2314 - val_loss: 1.5991 - val_mae: 1.5991 - lr: 2.0000e-04\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1944 - mae: 1.1944 - val_loss: 1.8463 - val_mae: 1.8463 - lr: 2.0000e-04\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2409 - mae: 1.2409 - val_loss: 1.5279 - val_mae: 1.5279 - lr: 2.0000e-04\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2638 - mae: 1.2638 - val_loss: 1.5419 - val_mae: 1.5419 - lr: 2.0000e-04\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2584 - mae: 1.2584 - val_loss: 1.5667 - val_mae: 1.5667 - lr: 2.0000e-04\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2184 - mae: 1.2184 - val_loss: 1.5286 - val_mae: 1.5286 - lr: 2.0000e-04\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1966 - mae: 1.1966 - val_loss: 1.5671 - val_mae: 1.5671 - lr: 2.0000e-04\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2615 - mae: 1.2615 - val_loss: 1.6632 - val_mae: 1.6632 - lr: 2.0000e-04\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.0995 - mae: 1.0995 - val_loss: 1.5265 - val_mae: 1.5265 - lr: 2.0000e-04\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2164 - mae: 1.2164 - val_loss: 1.5590 - val_mae: 1.5590 - lr: 2.0000e-04\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1774 - mae: 1.1774 - val_loss: 1.5240 - val_mae: 1.5240 - lr: 2.0000e-04\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1740 - mae: 1.1740 - val_loss: 1.5908 - val_mae: 1.5908 - lr: 2.0000e-04\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2354 - mae: 1.2354 - val_loss: 1.5265 - val_mae: 1.5265 - lr: 2.0000e-04\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2024 - mae: 1.2024 - val_loss: 1.6144 - val_mae: 1.6144 - lr: 2.0000e-04\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3235 - mae: 1.3235 - val_loss: 1.6125 - val_mae: 1.6125 - lr: 2.0000e-04\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2198 - mae: 1.2198 - val_loss: 1.5714 - val_mae: 1.5714 - lr: 2.0000e-04\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1602 - mae: 1.1602 - val_loss: 1.7602 - val_mae: 1.7602 - lr: 2.0000e-04\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2161 - mae: 1.2161 - val_loss: 1.5187 - val_mae: 1.5187 - lr: 2.0000e-04\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2488 - mae: 1.2488 - val_loss: 1.5668 - val_mae: 1.5668 - lr: 2.0000e-04\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2388 - mae: 1.2388 - val_loss: 1.6139 - val_mae: 1.6139 - lr: 2.0000e-04\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2253 - mae: 1.2253 - val_loss: 1.5283 - val_mae: 1.5283 - lr: 2.0000e-04\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1970 - mae: 1.1970 - val_loss: 1.5445 - val_mae: 1.5445 - lr: 2.0000e-04\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2589 - mae: 1.2589 - val_loss: 1.5769 - val_mae: 1.5769 - lr: 2.0000e-04\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2232 - mae: 1.2232 - val_loss: 1.5205 - val_mae: 1.5205 - lr: 2.0000e-04\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2224 - mae: 1.2224 - val_loss: 1.5285 - val_mae: 1.5285 - lr: 2.0000e-04\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2355 - mae: 1.2355 - val_loss: 1.5470 - val_mae: 1.5470 - lr: 2.0000e-04\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1672 - mae: 1.1672 - val_loss: 1.5519 - val_mae: 1.5519 - lr: 2.0000e-04\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2003 - mae: 1.2003 - val_loss: 1.5469 - val_mae: 1.5469 - lr: 2.0000e-04\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2310 - mae: 1.2310 - val_loss: 1.6171 - val_mae: 1.6171 - lr: 2.0000e-04\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2209 - mae: 1.2209 - val_loss: 1.5720 - val_mae: 1.5720 - lr: 2.0000e-04\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1944 - mae: 1.1944 - val_loss: 1.6591 - val_mae: 1.6591 - lr: 2.0000e-04\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2647 - mae: 1.2647 - val_loss: 1.6446 - val_mae: 1.6446 - lr: 2.0000e-04\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2564 - mae: 1.2564 - val_loss: 1.5529 - val_mae: 1.5529 - lr: 2.0000e-04\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1518 - mae: 1.1518 - val_loss: 1.5969 - val_mae: 1.5969 - lr: 2.0000e-04\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2223 - mae: 1.2223 - val_loss: 1.6187 - val_mae: 1.6187 - lr: 2.0000e-04\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2189 - mae: 1.2189 - val_loss: 1.5264 - val_mae: 1.5264 - lr: 2.0000e-04\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2785 - mae: 1.2785 - val_loss: 1.6036 - val_mae: 1.6036 - lr: 2.0000e-04\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1921 - mae: 1.1921 - val_loss: 1.6705 - val_mae: 1.6705 - lr: 2.0000e-04\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2423 - mae: 1.2423 - val_loss: 1.6423 - val_mae: 1.6423 - lr: 2.0000e-04\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1798 - mae: 1.1798 - val_loss: 1.5499 - val_mae: 1.5499 - lr: 4.0000e-05\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2325 - mae: 1.2325 - val_loss: 1.5599 - val_mae: 1.5599 - lr: 4.0000e-05\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1757 - mae: 1.1757 - val_loss: 1.5737 - val_mae: 1.5737 - lr: 4.0000e-05\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1429 - mae: 1.1429 - val_loss: 1.6299 - val_mae: 1.6299 - lr: 4.0000e-05\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.1640 - mae: 1.1640 - val_loss: 1.6174 - val_mae: 1.6174 - lr: 4.0000e-05\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1692 - mae: 1.1692 - val_loss: 1.6354 - val_mae: 1.6354 - lr: 4.0000e-05\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2170 - mae: 1.2170 - val_loss: 1.5983 - val_mae: 1.5983 - lr: 4.0000e-05\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1155 - mae: 1.1155 - val_loss: 1.5622 - val_mae: 1.5622 - lr: 4.0000e-05\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1643 - mae: 1.1643 - val_loss: 1.5793 - val_mae: 1.5793 - lr: 4.0000e-05\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1864 - mae: 1.1864 - val_loss: 1.5664 - val_mae: 1.5664 - lr: 4.0000e-05\n",
            "INFO:tensorflow:Assets written to: ram://ed991e9f-a208-4d2a-8858-c6d14d697823/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 여기부터 테스트 #####\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import os\n",
        "\n",
        "test = pd.read_csv('/content/test2.csv')\n",
        "test.drop('id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZE2cPB0Kbai0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "jrNA6DfGcch7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 위해 바꿨던 값들 테스트를 위해 test항목을 다시 바꿔줌.\n",
        "test = pd.get_dummies(data = test, columns = ['Gender'], prefix = 'Gender')\n",
        "foreign_body = test['Whole Weight'] - (test['Shucked Weight'] + test['Viscra Weight'] + test['Shell Weight'])\n",
        "test['foreign body'] = foreign_body\n",
        "test.loc[test['foreign body'] < 0 , 'foreign body'] = 0"
      ],
      "metadata": {
        "id": "VOmSK22dcd-U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_MF=test[(test['Gender_F']==1) | (test['Gender_M']==1)]\n",
        "test_MF_idx=test_MF.index\n",
        "test_I=test[test['Gender_I']==1]\n",
        "test_I_idx=test_I.index\n",
        "test_MF.drop(['Gender_F', 'Gender_I', 'Gender_M'], axis=1, inplace=True)\n",
        "test_I.drop(['Gender_F', 'Gender_I', 'Gender_M'], axis=1, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfDruVSwchnI",
        "outputId": "ac9f18df-461b-49eb-d922-ed2324096534"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ntest_MF=test_MF.drop('Target', axis=1)\n",
        "ntest_I=test_I.drop('Target', axis=1)"
      ],
      "metadata": {
        "id": "unD3uOydcoYg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 호출, MF와 I로 나누어서 모델을 선정하고 학습하였기에, 따로 호출해야 함.\n",
        "loaded_model_MF = joblib.load('/content/2016038005_김홍길_MF.pkl')\n",
        "loaded_model_I = joblib.load('/content/2016038005_김홍길_I.pkl')"
      ],
      "metadata": {
        "id": "PpquxkbZcrHq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_prediction = loaded_model_MF.predict(ntest_MF).flatten()\n",
        "Y_prediction_data = pd.DataFrame(Y_prediction)\n",
        "Y_prediction_data.to_csv('MF_test.csv',index=False)"
      ],
      "metadata": {
        "id": "xESZvZJrcviz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_prediction = loaded_model_I.predict(ntest_I).flatten()\n",
        "Y_prediction_data = pd.DataFrame(Y_prediction)\n",
        "Y_prediction_data.to_csv('I_test.csv',index=False)"
      ],
      "metadata": {
        "id": "QFeG1dCUcxj1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 점수 측정을 위한 함수\n",
        "def NMAE(true, pred):\n",
        "    mae = np.mean(np.abs(true-pred))\n",
        "    score = mae / np.mean(np.abs(true))\n",
        "    return score"
      ],
      "metadata": {
        "id": "Cv2bYeSBczo2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_MF = pd.read_csv('/content/MF_test.csv')\n",
        "result_I = pd.read_csv('/content/I_test.csv')"
      ],
      "metadata": {
        "id": "UZcvov0kc2AG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_MF.columns=['Target']\n",
        "result_I.columns=['Target']\n",
        "answer = pd.DataFrame(test_MF['Target'])\n",
        "answer.to_csv('answer.csv',index=False)"
      ],
      "metadata": {
        "id": "zfGnUysac4Pw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer=pd.read_csv('/content/answer.csv')\n",
        "result_MF = pd.concat([answer, result_MF], axis=1)"
      ],
      "metadata": {
        "id": "n_MYED0nc_Py"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.DataFrame(test_I['Target'])\n",
        "answer.to_csv('answer.csv',index=False)\n",
        "answer=pd.read_csv('/content/answer.csv')\n",
        "result_I = pd.concat([answer, result_I], axis=1)"
      ],
      "metadata": {
        "id": "e4_KAhqVdFu-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.concat([result_MF,result_I])"
      ],
      "metadata": {
        "id": "MXdowXIVdHxl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.columns = ['answer','prediction']"
      ],
      "metadata": {
        "id": "OCAm1Id_dJQm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = NMAE(result['answer'],result['prediction'])\n",
        "print('전복 나이 예측에 대한 nmae 값 : ' + str(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HGC86wFdKhY",
        "outputId": "05b6c01a-c15a-4ef9-db43-35c6201d5d2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전복 나이 예측에 대한 nmae 값 : 0.1637798242937853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(data=result,kde=True)"
      ],
      "metadata": {
        "id": "n4PKYHjWglmp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c3ff22a8-6656-4b5b-993d-0fe07547183e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74dfa7df90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기가 1에 가깝고, 산포도가 그래프에 가까울수록 예측이 잘된 것.\n",
        "sns.regplot(x = 'answer', y = 'prediction', data = result, scatter_kws={\"color\": \"#FC7F77\"}, line_kws={\"color\": \"black\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8qXZKRsbqZ_b",
        "outputId": "9a53cf94-3a81-4e9e-81eb-a9797e6df8b7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74e1019510>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYQZjtSTkVhY",
        "outputId": "5a3e1847-7996-41e7-f83c-233f77125d60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.833333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['prediction'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYMX8I19kczg",
        "outputId": "8abeb953-aeeb-4f59-ff5b-c00b9b10f4d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.127020153174604"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "err = np.abs(result['answer'] - result['prediction'])"
      ],
      "metadata": {
        "id": "zVG3cLQXklK9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azdg0j9Mk1z9",
        "outputId": "20b160fb-bd46-4327-8f92-65b09e5e3e07"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6105016055555554"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "err.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "290vJqVpk3ie",
        "outputId": "8e8a4c93-814b-49b0-9920-2bb1627477a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.281908"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "err.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPUlecPyk5Kt",
        "outputId": "bfcaba9a-2806-4fda-a6d0-260c424c716a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.013992000000000004"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=err,kde=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "RqlSvCSZlIiu",
        "outputId": "d599b043-289c-41bc-d384-6bac4d95654b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74e1093150>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
